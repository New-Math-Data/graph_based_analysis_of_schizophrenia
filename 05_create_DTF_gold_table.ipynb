{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dd7278a-27b0-4883-9eab-f1f2d06776e2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Overview - Graphing brain connectivity in schizophrenia from EEG data - Create DTF Graphs and Gold Table\n",
    "\n",
    "EEG analysis was carried out using:\n",
    "1. the raw EEG data, \n",
    "as well as the re-referenced data: \n",
    "2. the Average Reference Method and\n",
    "3. the Zero Reference Method.\n",
    "This allowed us to explore how the choice of reference electrode impacts connectivity outcomes.\n",
    "\n",
    "EEG data were analyzed using three connectivity methods: Phase-Locking Value (PLV), Phase-Lag Index (PLI), and Directed Transfer Function (DTF), and statistical indices based on graph theory. \n",
    "\n",
    "##### In this notebook we will:\n",
    "  * Graph analysis of EEG data measuring connectivity using three connectivity measures:\n",
    "    * Directed Transfer Function (DTF)\n",
    "    * Phase-Locking Value (PLV)\n",
    "    * Phase-Lag Index (PLI)\n",
    "##### This Notebook will use Directed Transfer Function (DTF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b8609d5-2f08-443f-99d1-d1cbc8436997",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###### We need to convert the REST Reference Method PySpark Dataframe to a Pandas Dataframe so we can use with the scipy, mne and numpy packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3aeb4936-8434-47a1-861e-33bdcc6b5dff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the data from the Butterworth Filtered Data REST Tables\n",
    "band_names = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
    "\n",
    "df_bands_rest = {}\n",
    "# Create Pandas DataFrames\n",
    "for band in band_names:\n",
    "    df_bands_rest[band] = spark.sql(f\"SELECT * FROM main.solution_accelerator.butter_rest_{band}_gold ORDER BY time ASC\").toPandas()\n",
    "    # Get distinct values from the 'patient_id' column\n",
    "    patient_ids = df_bands_rest[band]['patient_id'].unique()\n",
    "    print(f\"patient_ids:::{patient_ids}\")\n",
    "# display(df_bands_rest[band])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3275170a-db92-4461-bd50-3f5134ceeb6f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###### We need to convert the Average Reference Method PySpark Dataframe to a Pandas Dataframe so we can use with the scipy, mne and numpy packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "936226df-2b42-4790-bbbf-3a478c884108",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create PySpark DataFrames\n",
    "band_names = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
    "\n",
    "df_bands_avg = {}\n",
    "\n",
    "for band in band_names:\n",
    "    df_bands_avg[band] = spark.sql(f\"SELECT * FROM main.solution_accelerator.butter_avg_{band}_gold ORDER BY time ASC\").toPandas()\n",
    "    # Get distinct values from the 'patient_id' column\n",
    "    patient_ids = df_bands_avg[band]['patient_id'].unique()\n",
    "    print(f\"patient_ids:::{patient_ids}\")\n",
    "    display(df_bands_avg[band])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "596edade-1725-42ba-b078-d51ff17fc8aa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Graph analysis of EEG data measuring connectivity using Directed Transfer Function (DTF) connectivity measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c16b200-1a6b-4374-8df7-70e62f763c12",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Directed Transfer Function (DTF)\n",
    "Directed Transfer Function (DTF) is a frequency-domain measure derived from multivariate autoregressive (MVAR) modeling of EEG signals. It estimates the directed influence or connectivity between different brain regions in the frequency domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6e15b56-a511-4823-81d9-892fa4a0058f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Helper library with many built-in functions\n",
    "%pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af2aca4f-76b3-4951-bf45-0c45a935d1ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "\n",
    "band_names = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
    "\n",
    "# Sampling rate in Hz\n",
    "sfreq = 250\n",
    "\n",
    "mne_raw_all = {}\n",
    "\n",
    "# Create Pandas DataFrames\n",
    "for band in band_names:\n",
    "    mne_raw_all[band] = {}\n",
    "    \n",
    "    # Get channel names , extract patient_id column\n",
    "    ch_names = [c for c in df_bands_rest[band].columns if c not in ['patient_id', 'time']]\n",
    "    # print(f\"ch_names:::{ch_names}\")\n",
    "\n",
    "    # Extract patient_id column\n",
    "    pt_names = list(df_bands_rest[band]['patient_id'].unique())\n",
    "    # print(f\"patient_names:::{pt_names}\")\n",
    "\n",
    "    for pt in pt_names:\n",
    "        print(\"PATIENT_ID::\", pt)\n",
    "        df_pt_data = df_bands_rest[band].loc[df_bands_rest[band]['patient_id'] == pt]\n",
    "        df_pt_data = df_pt_data.drop(columns=['patient_id', 'time'])    \n",
    "        # print(\"LEN::\", len(df_pt_data.index))\n",
    "        \n",
    "        # Convert Pandas Dataframe to Numpy Array for each patient\n",
    "        np_pt_data = df_pt_data.to_numpy() \n",
    "\n",
    "        # Create an info structure needed by MNE\n",
    "        info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types='eeg')\n",
    "        \n",
    "        # Create the MNE Raw object\n",
    "        mne_raw_pt = mne.io.RawArray(np_pt_data.T, info)\n",
    "        \n",
    "        # The mne raw data object gives us time, assess it as `data, times = raw[:]`  \n",
    "        # Channel mapping\n",
    "        mne_raw_all[band][pt] = mne_raw_pt.set_montage('standard_1020')\n",
    "        \n",
    "        # # Plot the data so we can compare graphs to reference methods later\n",
    "        # print(f\"Patient ID: {pt}\")\n",
    "        # mne_raw_all[band][pt] .plot(scalings=dict(eeg=50), title=(f\"Patient ID: {pt}\"), start=150, duration=100)\n",
    "        # print(f\"Patient ID: {pt}\")\n",
    "        # mne_raw_all[band][pt].plot_sensors(ch_type=\"eeg\", title=(f\"Patient ID: {pt}\"))\n",
    "        # print(f\"Patient ID: {pt}\")\n",
    "        # spectrum = mne_raw_all[band][pt].compute_psd().plot(average=True, picks=\"data\", exclude=\"bads\", amplitude=False)\n",
    "        \n",
    "# Now we have our MNE Raw objects and are ready for further analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4dcb187-21e5-40b0-b789-27a1b1a6607d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import hilbert\n",
    "\n",
    "# Function to compute analytic signal using Hilbert transform\n",
    "def analytic_signal(sig):\n",
    "    return hilbert(sig)\n",
    "\n",
    "# Function to compute covariance matrix\n",
    "def covariance_matrix(H):\n",
    "    return np.cov(H)\n",
    "\n",
    "# Function to compute Directed Transfer Function (DTF)\n",
    "def dtf(H):\n",
    "    C = covariance_matrix(H)\n",
    "    Pxx = np.diag(C)\n",
    "    D = np.dot(np.dot(H, np.linalg.inv(C)), H.T)\n",
    "    D /= Pxx[:, None]\n",
    "    D = np.abs(D)\n",
    "    return D\n",
    "\n",
    "def compute_dtf_matrix(pd_df):\n",
    "    \"\"\"\n",
    "    Compute the Directed Transfer Function (DTF) adjacency matrix for multiple EEG channels.\n",
    "\n",
    "    Parameters:\n",
    "    pd_df (pandas DataFrame): DataFrame containing EEG signals as columns.\n",
    "\n",
    "    Returns:\n",
    "    numpy array: Adjacency matrix where entry (i, j) represents the DTF from channel j to channel i.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare a 2D array where each column is a signal\n",
    "    signals = pd_df.values\n",
    "    display(signals)\n",
    "    H = analytic_signal(signals)  # Apply Hilbert transform to the entire set of signals\n",
    "    print(\"H::::\")\n",
    "    # display(H)\n",
    "\n",
    "    # # Compute DTF for the matrix of signals\n",
    "    dtf_matrix = dtf(H)\n",
    "\n",
    "    # return dtf_matrix\n",
    "\n",
    "band_names = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
    "for band in band_names:\n",
    "    # Get channel names as a list. Drop columns that are not electrode channels\n",
    "    columns_to_drop = ['patient_id', 'time']\n",
    "    patients = df_bands_rest[band]['patient_id'].unique().tolist()\n",
    "    print(patients);\n",
    "    for pt in patients:\n",
    "        df_pt = df_bands_rest[band].loc[df_bands_rest[band]['patient_id'] == pt].drop(columns=columns_to_drop).head(1000)\n",
    "        channel_names = list(df_pt.head())\n",
    "        print(f\"channel_names:::{channel_names}\")\n",
    "        num_channels = len(channel_names)\n",
    "        display(df_pt)\n",
    "        # Compute DTF for all pairs of channels\n",
    "        dtf_matrix = np.zeros((num_channels, num_channels))\n",
    "\n",
    "        compute_dtf_matrix(df_pt)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [
    {
     "elements": [],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "2edfc3e1-1d14-4238-aa82-e049cd21fef7",
     "origId": 3554137769111096,
     "title": "SA_Graphing_Schizophrenia",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_create_DTF_gold_table",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
