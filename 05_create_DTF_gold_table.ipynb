{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dd7278a-27b0-4883-9eab-f1f2d06776e2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Overview - Graphing brain connectivity in schizophrenia from EEG data - Create DTF Graphs and Gold Table\n",
    "\n",
    "EEG analysis was carried out using:\n",
    "1. the raw EEG data, \n",
    "as well as the re-referenced data: \n",
    "2. the Average Reference Method and\n",
    "3. the Zero Reference Method.\n",
    "This allowed us to explore how the choice of reference electrode impacts connectivity outcomes.\n",
    "\n",
    "EEG data were analyzed using three connectivity methods: Phase-Locking Value (PLV), Phase-Lag Index (PLI), and Directed Transfer Function (DTF), and statistical indices based on graph theory. \n",
    "\n",
    "##### In this notebook we will:\n",
    "  * Graph analysis of EEG data measuring connectivity using three connectivity measures:\n",
    "    * Directed Transfer Function (DTF)\n",
    "    * Phase-Locking Value (PLV)\n",
    "    * Phase-Lag Index (PLI)\n",
    "##### This Notebook will use Directed Transfer Function (DTF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b8609d5-2f08-443f-99d1-d1cbc8436997",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###### We need to convert the REST Reference Method PySpark Dataframe to a Pandas Dataframe so we can use with the scipy, mne and numpy packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3aeb4936-8434-47a1-861e-33bdcc6b5dff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the data from the Butterworth Filtered Data REST Tables\n",
    "band_names = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
    "\n",
    "df_bands_rest = {}\n",
    "# Create Pandas DataFrames\n",
    "for band in band_names:\n",
    "    df_bands_rest[band] = spark.sql(f\"SELECT * FROM main.solution_accelerator.butter_rest_{band}_gold ORDER BY time ASC\").toPandas()\n",
    "    # Get distinct values from the 'patient_id' column\n",
    "    patient_ids = df_bands_rest[band]['patient_id'].unique()\n",
    "    print(f\"patient_ids:::{patient_ids}\")\n",
    "# display(df_bands_rest[band])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3275170a-db92-4461-bd50-3f5134ceeb6f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###### We need to convert the Average Reference Method PySpark Dataframe to a Pandas Dataframe so we can use with the scipy, mne and numpy packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "936226df-2b42-4790-bbbf-3a478c884108",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create PySpark DataFrames\n",
    "band_names = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
    "\n",
    "df_bands_avg = {}\n",
    "\n",
    "for band in band_names:\n",
    "    df_bands_avg[band] = spark.sql(f\"SELECT * FROM main.solution_accelerator.butter_avg_{band}_gold ORDER BY time ASC\").toPandas()\n",
    "    # Get distinct values from the 'patient_id' column\n",
    "    patient_ids = df_bands_avg[band]['patient_id'].unique()\n",
    "    print(f\"patient_ids:::{patient_ids}\")\n",
    "    display(df_bands_avg[band])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "596edade-1725-42ba-b078-d51ff17fc8aa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Graph analysis of EEG data measuring connectivity using Directed Transfer Function (DTF) connectivity measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c16b200-1a6b-4374-8df7-70e62f763c12",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Directed Transfer Function (DTF)\n",
    "Directed Transfer Function (DTF) is a frequency-domain measure derived from multivariate autoregressive (MVAR) modeling of EEG signals. It estimates the directed influence or connectivity between different brain regions in the frequency domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6e15b56-a511-4823-81d9-892fa4a0058f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Helper library with many built-in functions\n",
    "%pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af2aca4f-76b3-4951-bf45-0c45a935d1ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "\n",
    "band_names = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
    "\n",
    "# Sampling rate in Hz\n",
    "sfreq = 250\n",
    "\n",
    "mne_raw_all = {}\n",
    "\n",
    "# Create Pandas DataFrames\n",
    "for band in band_names:\n",
    "    mne_raw_all[band] = {}\n",
    "    \n",
    "    # Get channel names , extract patient_id column\n",
    "    ch_names = [c for c in df_bands_rest[band].columns if c not in ['patient_id', 'time']]\n",
    "    # print(f\"ch_names:::{ch_names}\")\n",
    "\n",
    "    # Extract patient_id column\n",
    "    pt_names = list(df_bands_rest[band]['patient_id'].unique())\n",
    "    # print(f\"patient_names:::{pt_names}\")\n",
    "\n",
    "    for pt in pt_names:\n",
    "        print(\"PATIENT_ID::\", pt)\n",
    "        df_pt_data = df_bands_rest[band].loc[df_bands_rest[band]['patient_id'] == pt]\n",
    "        df_pt_data = df_pt_data.drop(columns=['patient_id', 'time'])    \n",
    "        # print(\"LEN::\", len(df_pt_data.index))\n",
    "        \n",
    "        # Convert Pandas Dataframe to Numpy Array for each patient\n",
    "        np_pt_data = df_pt_data.to_numpy() \n",
    "\n",
    "        # Create an info structure needed by MNE\n",
    "        info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types='eeg')\n",
    "        \n",
    "        # Create the MNE Raw object\n",
    "        mne_raw_pt = mne.io.RawArray(np_pt_data.T, info)\n",
    "        \n",
    "        # The mne raw data object gives us time, assess it as `data, times = raw[:]`  \n",
    "        # Channel mapping\n",
    "        mne_raw_all[band][pt] = mne_raw_pt.set_montage('standard_1020')\n",
    "        \n",
    "        # # Plot the data so we can compare graphs to reference methods later\n",
    "        # print(f\"Patient ID: {pt}\")\n",
    "        # mne_raw_all[band][pt] .plot(scalings=dict(eeg=50), title=(f\"Patient ID: {pt}\"), start=150, duration=100)\n",
    "        # print(f\"Patient ID: {pt}\")\n",
    "        # mne_raw_all[band][pt].plot_sensors(ch_type=\"eeg\", title=(f\"Patient ID: {pt}\"))\n",
    "        # print(f\"Patient ID: {pt}\")\n",
    "        # spectrum = mne_raw_all[band][pt].compute_psd().plot(average=True, picks=\"data\", exclude=\"bads\", amplitude=False)\n",
    "        \n",
    "# Now we have our MNE Raw objects and are ready for further analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a5670c3-9382-49b5-8c24-172c604a7a17",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from scipy.linalg import inv\n",
    "import scot\n",
    "\n",
    "band_names = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
    "\n",
    "def compute_dtf(data, n_channels, n_times, order=5):\n",
    "    \"\"\"\n",
    "    Compute the Directed Transfer Function (DTF) from multichannel time series data.\n",
    "\n",
    "    Parameters:\n",
    "    data : ndarray\n",
    "        Multichannel time series data of shape (n_channels, n_times).\n",
    "    order : int\n",
    "        Order of the MVAR model.\n",
    "\n",
    "    Returns:\n",
    "    dtf : ndarray\n",
    "        DTF matrix of shape (n_channels, n_channels, n_frequencies).\n",
    "    \"\"\"\n",
    "\n",
    "    # n_channels, n_times = data.shape\n",
    "    n_frequencies = n_times // 2 + 1  # Number of positive frequencies\n",
    "\n",
    "    # Fit MVAR model\n",
    "    X = np.zeros((n_times - order, n_channels * order))\n",
    "    Y = np.zeros((n_times - order, n_channels))\n",
    "    for t in range(order, n_times):\n",
    "        X[t - order] = np.hstack([data[:, t - k] for k in range(1, order + 1)])\n",
    "        Y[t - order] = data[:, t]\n",
    "\n",
    "    A = np.linalg.lstsq(X, Y, rcond=None)[0].T\n",
    "    A = A.reshape(n_channels, n_channels, order)\n",
    "\n",
    "    # Compute DTF\n",
    "    H = np.zeros((n_channels, n_channels, n_frequencies), dtype=complex)\n",
    "    dtf = np.zeros((n_channels, n_channels, n_frequencies))\n",
    "\n",
    "    for f in range(n_frequencies):\n",
    "        omega = 2 * np.pi * f / n_times\n",
    "        Af = np.sum([A[:, :, k] * np.exp(-1j * omega * (k + 1)) for k in range(order)], axis=0)\n",
    "        H[:, :, f] = inv(np.eye(n_channels) - Af)\n",
    "\n",
    "    for i in range(n_channels):\n",
    "        for j in range(n_channels):\n",
    "            dtf[i, j, :] = np.abs(H[i, j, :]) / np.sqrt(np.sum(np.abs(H[i, :, :])**2, axis=0))\n",
    "\n",
    "    return dtf\n",
    "\n",
    "def calculate_dtf(data_intervals, steps, channels, sample_rate, bands, flag):\n",
    "    num_bands = sum(bands)\n",
    "    intervals = (len(steps)) - flag\n",
    "    matrix = np.zeros(shape=((intervals * num_bands), channels, channels))\n",
    "    start, stop = 0, channels\n",
    "    \n",
    "    ws = scot.Workspace({'model_order': channels - 5}, reducedim = 'no_pca', nfft= int(sample_rate/2), fs = sample_rate)\n",
    "    \n",
    "    f = np.arange(0, int(sample_rate/2))\n",
    "    \n",
    "    #Loop over the number of intervals\n",
    "    for k in range(intervals):\n",
    "        #If there is more than one interval, the new start is the last stop and we calculate the new stop with the number of channels. \n",
    "        if k!=0:\n",
    "            start = stop\n",
    "            stop+= channels\n",
    "            \n",
    "        data = []\n",
    "        for h in range(start, stop):\n",
    "            data.append(data_intervals[h])\n",
    "        \n",
    "        ws.set_data(data)\n",
    "        ws.do_mvarica()\n",
    "        ws.fit_var()\n",
    "        results = ws.get_connectivity('DTF')\n",
    "        #Loop over \n",
    "        for x,i in enumerate(range(start, stop)):\n",
    "            for y,j in enumerate(range(start, stop)):\n",
    "                delta, theta, alpha, beta, gamma = frequency_bands(f, results[x][y])\n",
    "                r=0\n",
    "                for z, item in enumerate ([delta, theta, alpha, beta, gamma]):\n",
    "                    if bands[z]:\n",
    "                        if (len(item)!= 0):\n",
    "                            matrix[(k * num_bands) + r][x,y] = item.mean()\n",
    "                        else:\n",
    "                            matrix[(k * num_bands) + r][x,y] = 0\n",
    "                        r+=1                  \n",
    "    return matrix\n",
    "\n",
    "pt_all = ['s11', 'h13']\n",
    "dtf_matrix_dict = {}\n",
    "for band in band_names:\n",
    "    for pt in mne_raw_all[band]:\n",
    "\n",
    "        # Get channel names , extract patient_id column\n",
    "        ch_names = [c for c in df_bands_rest[band].columns if c not in ['patient_id', 'time']]\n",
    "        # print(f\"ch_names:::{ch_names}\")\n",
    "\n",
    "        # Preprocess the data (e.g., filtering and epoching)\n",
    "        # mne_raw_all[band][pt].filter(1.0, 30.0, method='iir')  # Band-pass filter between 1 and 30 Hz\n",
    "  \n",
    "        # events = mne.find_events(mne_raw_all[band][pt], stim_channel=ch_names, min_duration=1)\n",
    "\n",
    "        # epochs = mne.Epochs(mne_raw_all[band][pt], events, event_id=1, tmin=-0.2, tmax=0.5, preload=True)\n",
    "\n",
    "        # Get data from epochs (shape: n_epochs, n_channels, n_times)\n",
    "        # data = epochs.get_data()\n",
    "\n",
    "        # # Average across epochs to get (n_channels, n_times)\n",
    "        # data_avg = np.mean(mne_raw_all[band][pt], axis=0)\n",
    "        # data_avg = np.expand_dims(data_avg, axis=0)  # Add an extra dimension\n",
    "        # data_avg = np.transpose(data_avg, (1, 0))  # Transpose to shape (n_channels, n_times)\n",
    "\n",
    "        n_channels = len(mne_raw_all[band][pt].info['ch_names'])\n",
    "        n_times = mne_raw_all[band][pt].n_times\n",
    "\n",
    "        # Compute DTF\n",
    "        dtf_matrix_dict[mne_raw_all[band][pt]] = compute_dtf(data=mne_raw_all[band][pt], n_channels=n_channels, n_times=n_times)\n",
    "        # print(\"DTF matrix shape:\", dtf_matrix.shape)\n",
    "       \n",
    "        # # Plot the DTF matrix at a specific frequency (e.g., frequency index 10)\n",
    "        # import matplotlib.pyplot as plt\n",
    "        # plt.imshow(dtf_matrix[:, :, 10], aspect='auto', origin='lower')\n",
    "        # plt.title('Directed Transfer Function (DTF) at frequency index 10')\n",
    "        # plt.xlabel('Channel')\n",
    "        # plt.ylabel('Channel')\n",
    "        # plt.colorbar(label='DTF value')\n",
    "        # plt.show()\n",
    "\n",
    "        # # Plot the DTF matrix for a specific frequency band (e.g., alpha band 8-12 Hz)\n",
    "        # import matplotlib.pyplot as plt\n",
    "        # alpha_band = (8, 12)\n",
    "        # alpha_idx = np.where((fmin <= alpha_band[0]) & (fmax >= alpha_band[1]))[0]\n",
    "        # plt.imshow(np.mean(dtf_matrix[:, :, alpha_idx], axis=-1), aspect='auto', origin='lower')\n",
    "        # plt.title('Directed Transfer Function (DTF) - Alpha Band')\n",
    "        # plt.xlabel('Channel')\n",
    "        # plt.ylabel('Channel')\n",
    "        # plt.colorbar(label='DTF value')\n",
    "        # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ebd13da-f1f5-4913-a665-4221235b178a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import mne\n",
    "# import numpy as np\n",
    "# from scipy.signal import coherence, csd\n",
    "# from numpy.linalg import inv\n",
    "\n",
    "# def compute_dtf(data, sfreq, freq_band, n_channels):\n",
    "#     \"\"\"\n",
    "#     Compute Directed Transfer Function (DTF) for EEG data.\n",
    "    \n",
    "#     Parameters:\n",
    "#     data : np.ndarray\n",
    "#         Multichannel time series data (channels x time points).\n",
    "#     sfreq : float\n",
    "#         Sampling frequency of the data.\n",
    "#     freq_band : tuple\n",
    "#         Frequency band for DTF calculation (e.g., (8, 12) for alpha band).\n",
    "#     n_channels : int\n",
    "#         Number of channels.\n",
    "        \n",
    "#     Returns:\n",
    "#     dtf : np.ndarray\n",
    "#         Directed Transfer Function matrix (channels x channels x frequencies).\n",
    "#     \"\"\"\n",
    "#     n_times = data.shape[1]\n",
    "#     freqs = np.fft.rfftfreq(n_times, 1/sfreq)\n",
    "#     freq_mask = (freqs >= freq_band[0]) & (freqs <= freq_band[1])\n",
    "\n",
    "#     # Compute Cross-Spectral Density (CSD) matrix\n",
    "#     csd_matrix = np.zeros((n_channels, n_channels, len(freqs)), dtype=complex)\n",
    "#     for i in range(n_channels):\n",
    "#         for j in range(n_channels):\n",
    "#             f, Pxy = csd(data[i], data[j], sfreq, nperseg=n_times)\n",
    "#             csd_matrix[i, j, :] = Pxy\n",
    "\n",
    "#     # Compute DTF\n",
    "#     dtf = np.zeros((n_channels, n_channels, len(freqs)))\n",
    "#     for f_idx, freq in enumerate(freqs):\n",
    "#         if freq_mask[f_idx]:\n",
    "#             H = np.zeros((n_channels, n_channels), dtype=complex)\n",
    "#             for i in range(n_channels):\n",
    "#                 for j in range(n_channels):\n",
    "#                     H[i, j] = csd_matrix[i, j, f_idx]\n",
    "\n",
    "#             H_inv = inv(H)\n",
    "#             for i in range(n_channels):\n",
    "#                 for j in range(n_channels):\n",
    "#                     dtf[i, j, f_idx] = np.abs(H_inv[i, j])**2 / np.sum(np.abs(H_inv[i, :])**2)\n",
    "#     return dtf\n",
    "\n",
    "# band_names = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
    "\n",
    "# # Define the sampling frequency (in Hz)\n",
    "# sampling_freq = 250 \n",
    "\n",
    "# # Define frequency bands\n",
    "# frequency_bands = {\n",
    "#     'delta': (2, 4),\n",
    "#     'theta': (4.5, 7.5),\n",
    "#     'alpha': (8, 12.5),\n",
    "#     'beta': (13, 30),\n",
    "#     'gamma': (30, 45)\n",
    "# }\n",
    "\n",
    "# times: []\n",
    "# channel_names: []\n",
    "\n",
    "# # Transpose data for each band and store in a dictionary\n",
    "# transposed_data = {}\n",
    "# for band in band_names:\n",
    "#     # Get the times\n",
    "#     times = df_bands_rest[band]['time'].values.tolist()\n",
    "\n",
    "#     # Get channel names as a list. Drop columns that are not electrode channels\n",
    "#     columns_to_drop = ['patient_id', 'time']\n",
    "#     channel_names = df_bands_rest[band].drop(columns=columns_to_drop).columns.tolist()\n",
    "#     print(f\"channel_names:::{channel_names}\")\n",
    "\n",
    "#     # Extract data for the current band and transpose\n",
    "#     rest_data_T= df_bands_rest[band][channel_names].values.T  # Transpose to get shape (n_channels, n_times)\n",
    "\n",
    "#     # Store transposed data in the dictionary\n",
    "#     transposed_data[band] = rest_data_T\n",
    "\n",
    "#     print(f\"LEN of channels:::{len(channel_names)}\")\n",
    "#     print(f\"list(frequency_bands.values()):::{list(frequency_bands.values())}\")\n",
    "\n",
    "#     # Compute DTF, `data` with shape (channels x time points)\n",
    "#     for freq_range in list(frequency_bands.values()):\n",
    "#         dtf = compute_dtf(data=transposed_data[band], sfreq=sampling_freq, freq_band=freq_range, n_channels=len(channel_names))\n",
    "#         print(dtf[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4dcb187-21e5-40b0-b789-27a1b1a6607d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from scipy.signal import hilbert\n",
    "\n",
    "# # Function to compute analytic signal using Hilbert transform\n",
    "# def analytic_signal(sig):\n",
    "#     return hilbert(sig)\n",
    "\n",
    "# # Function to compute covariance matrix\n",
    "# def covariance_matrix(H):\n",
    "#     return np.cov(H)\n",
    "\n",
    "# # Function to compute Directed Transfer Function (DTF)\n",
    "# def dtf(H):\n",
    "#     C = covariance_matrix(H)\n",
    "#     Pxx = np.diag(C)\n",
    "#     D = np.dot(np.dot(H, np.linalg.inv(C)), H.T)\n",
    "#     D /= Pxx[:, None]\n",
    "#     D = np.abs(D)\n",
    "#     return D\n",
    "\n",
    "# def compute_dtf_matrix(pd_df):\n",
    "#     \"\"\"\n",
    "#     Compute the Directed Transfer Function (DTF) adjacency matrix for multiple EEG channels.\n",
    "\n",
    "#     Parameters:\n",
    "#     pd_df (pandas DataFrame): DataFrame containing EEG signals as columns.\n",
    "\n",
    "#     Returns:\n",
    "#     numpy array: Adjacency matrix where entry (i, j) represents the DTF from channel j to channel i.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Prepare a 2D array where each column is a signal\n",
    "#     signals = pd_df.values\n",
    "#     display(signals)\n",
    "#     H = analytic_signal(signals)  # Apply Hilbert transform to the entire set of signals\n",
    "#     print(\"H::::\")\n",
    "#     # display(H)\n",
    "\n",
    "#     # # Compute DTF for the matrix of signals\n",
    "#     dtf_matrix = dtf(H)\n",
    "\n",
    "#     # return dtf_matrix\n",
    "\n",
    "# band_names = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
    "# for band in band_names:\n",
    "#     # Get channel names as a list. Drop columns that are not electrode channels\n",
    "#     columns_to_drop = ['patient_id', 'time']\n",
    "#     patients = df_bands_rest[band]['patient_id'].unique().tolist()\n",
    "#     print(patients);\n",
    "#     for pt in patients:\n",
    "#         df_pt = df_bands_rest[band].loc[df_bands_rest[band]['patient_id'] == pt].drop(columns=columns_to_drop).head(1000)\n",
    "#         channel_names = list(df_pt.head())\n",
    "#         print(f\"channel_names:::{channel_names}\")\n",
    "#         num_channels = len(channel_names)\n",
    "#         display(df_pt)\n",
    "#         # Compute DTF for all pairs of channels\n",
    "#         dtf_matrix = np.zeros((num_channels, num_channels))\n",
    "\n",
    "#         compute_dtf_matrix(df_pt)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [
    {
     "elements": [],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "2edfc3e1-1d14-4238-aa82-e049cd21fef7",
     "origId": 3554137769111096,
     "title": "SA_Graphing_Schizophrenia",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_create_DTF_gold_table",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
