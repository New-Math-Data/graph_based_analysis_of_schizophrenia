{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dd7278a-27b0-4883-9eab-f1f2d06776e2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Overview - Graphing brain connectivity in schizophrenia from EEG data\n",
    "\n",
    "EEG analysis was carried out using:\n",
    "1. the raw EEG data, \n",
    "as well as the re-referenced data: \n",
    "2. the Average Reference Method and\n",
    "3. the Zero Reference Method.\n",
    "This allowed us to explore how the choice of reference electrode impacts connectivity outcomes.\n",
    "\n",
    "EEG data were analyzed using three connectivity methods: Phase-Locking Value (PLV), Phase-Lag Index (PLI), and Directed Transfer Function (DTF), and statistical indices based on graph theory. \n",
    "\n",
    "##### In this notebook we will:\n",
    "  * Graph analysis of EEG data measuring connectivity using three connectivity measures:\n",
    "    * Directed Transfer Function (DTF)\n",
    "    * Phase-Locking Value (PLV)\n",
    "    * Phase-Lag Index (PLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3aeb4936-8434-47a1-861e-33bdcc6b5dff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a temporary DataFrame for data cleaning purposes\n",
    "\n",
    "# Filter the DataFrame where `subject` == `c` (control group) and where `subject` == `s` (study group) \n",
    "\n",
    "# Zero Reference Method Table\n",
    "df_zero_ref_C = spark.sql(\"\"\"SELECT * FROM main.solution_accelerator.eeg_zero_ref_data_silver WHERE subject = 'c' \"\"\")\n",
    "df_zero_ref_S = spark.sql(\"\"\"SELECT * FROM main.solution_accelerator.eeg_zero_ref_data_silver WHERE subject = 's' \"\"\")\n",
    "\n",
    "# Average Reference Method Table\n",
    "df_avg_ref_C = spark.sql(\"\"\"SELECT * FROM main.solution_accelerator.eeg_avg_ref_data_silver WHERE subject = 'c' \"\"\")\n",
    "df_avg_ref_S = spark.sql(\"\"\"SELECT * FROM main.solution_accelerator.eeg_avg_ref_data_silver WHERE subject = 's' \"\"\")\n",
    "\n",
    "# Show the DataFrame\n",
    "display(df_zero_ref_C)\n",
    "display(df_zero_ref_S)\n",
    "\n",
    "display(df_avg_ref_C)\n",
    "display(df_avg_ref_S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "011793ba-453f-4bf1-a88c-d3a7e7b179a6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### We need to convert the PySpark Dataframe to a Pandas Dataframe so we can use with the scipy, mne and numpy packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1732437-8ece-4a46-8ceb-6a699496e9b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert our PySpark Dataframe to a Pandas Dataframe\n",
    "df_zero_ref_C_pd = df_zero_ref_C.toPandas()\n",
    "df_zero_ref_S_pd = df_zero_ref_S.toPandas()\n",
    "\n",
    "df_avg_ref_C_pd = df_avg_ref_C.toPandas()\n",
    "df_avg_ref_S_pd = df_avg_ref_S.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "596edade-1725-42ba-b078-d51ff17fc8aa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Graph analysis of EEG data measuring connectivity using three connectivity measures\n",
    "###### Prepared the dataframes have been grouped by `subject` type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bf38b5a-3e0c-40e7-818d-805e8d85d515",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install mne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c16b200-1a6b-4374-8df7-70e62f763c12",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Directed Transfer Function (DTF)\n",
    "Directed Transfer Function (DTF) is a frequency-domain measure derived from multivariate autoregressive (MVAR) modeling of EEG signals. It estimates the directed influence or connectivity between different brain regions in the frequency domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ebd13da-f1f5-4913-a665-4221235b178a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mne\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# 1. Load the data from the Silver tables\n",
    "\n",
    "# The Zero Reference Method gave us associated times for the frequencies\n",
    "\n",
    "# Get the times out\n",
    "times = df_zero_ref_C['data_time'].values\n",
    "\n",
    "# Get column names as a list\n",
    "column_names = df_zero_ref_C.columns\n",
    "\n",
    "# Drop columns that are not electrodes\n",
    "columns_to_drop = ['patient_id', 'data_time', 'subject']\n",
    "df_channels = df_zero_ref_C.drop(*columns_to_drop)\n",
    "\n",
    "# Get channel names as a list\n",
    "channel_names = list(df_channels)\n",
    "\n",
    "eeg_data = df_zero_ref_C[channel_names].values.T  # Transpose to get shape (n_channels, n_times)\n",
    "\n",
    "# 2. Create an MNE Raw Object\n",
    "\n",
    "# Define the sampling frequency (in Hz)\n",
    "sampling_freq = 250 \n",
    "\n",
    "# Create an MNE Info object\n",
    "info = mne.create_info(ch_names=channel_names, sfreq=sampling_freq, ch_types='eeg')\n",
    "\n",
    "# Create the MNE RawArray object\n",
    "raw = mne.io.RawArray(eeg_data, info, times)\n",
    "\n",
    "# # Optionally, set the times manually if they are not equidistant\n",
    "# raw.set_times(times)\n",
    "\n",
    "# 3. Graph and Analyze the Data with MNE\n",
    "\n",
    "# Plot the data\n",
    "raw.plot()\n",
    "\n",
    "# Apply a band-pass filter\n",
    "raw.filter(1., 50.)\n",
    "\n",
    "# Create epochs \n",
    "events = np.array([[100, 0, 1], [300, 0, 2], [500, 0, 1]])  # Replace with your actual events\n",
    "event_id = {'Event1': 1, 'Event2': 2}\n",
    "epochs = mne.Epochs(raw, events, event_id, tmin=-0.2, tmax=0.5, baseline=(None, 0))\n",
    "\n",
    "# Compute and plot evoked response\n",
    "evoked = epochs['Event1'].average()\n",
    "evoked.plot()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [
    {
     "elements": [],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "2edfc3e1-1d14-4238-aa82-e049cd21fef7",
     "origId": 146926676179412,
     "title": "SA_Graphing_Schizophrenia",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DFT",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
